{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import data_utils.data_utils_celeba_pytorch5 as data_utils\n",
    "import data_utils.network_tuning23 as network_tuning\n",
    "from IPython.display import clear_output\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# Load functions\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout2d, MaxPool2d, BatchNorm2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = [73,60,3]\n",
    "# Paths to data\n",
    "# Root directory for dataset\n",
    "dataroot = 'C:\\\\Users\\\\cfthe\\\\OneDrive\\\\DTU\\\\Kandidat\\\\Deep\\\\AlgorithmicFairness'\n",
    "TRAIN_PATH =  dataroot + \"\\\\Data\\\\train.csv\" \n",
    "VALID_PATH = dataroot + \"\\\\Data\\\\valid.csv\" \n",
    "TEST_PATH = dataroot + \"\\\\Data\\\\test.csv\" \n",
    "IMAGE_PATHS = \"C:\\\\Users\\\\cfthe\\\\OneDrive\\\\DTU\\\\Kandidat\\\\Deep\\\\celebA_resize3\\\\\"\n",
    "TARGET_COL = 'Smiling'\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# train holds both X (input) and t (target/truth)\n",
    "data_train = data_utils.CelebADataset(TRAIN_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\n",
    "data_valid = data_utils.CelebADataset(VALID_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\n",
    "\n",
    "#tuning the network round 1\n",
    "df = pd.DataFrame(index=list(range(1,13)), columns=['layers','activations','conv_out_channels','kernel_size','conv_stride','maxpool'\\\n",
    "                                                    ,'dropout','batchnorm','optimizer','learning_rate','weight_decay','batch_size','num_epochs'\\\n",
    "                                                    ,'net','train_loss','train_accs','valid_loss','valid_accs'])\n",
    "\n",
    "\n",
    "df['layers'] = 1\n",
    "\n",
    "#adjust activation function\n",
    "for i in range(1,7):\n",
    "    df.at[i,'activations'] = [relu, relu, relu, relu]\n",
    "for i in range(7,13):\n",
    "    df.at[i,'activations'] = [tanh, tanh, tanh, tanh]\n",
    "IMAGE_SHAPE = [73,60,3]\n",
    "df['conv_out_channels'] = 16\n",
    "df['kernel_size'] = 5\n",
    "df['conv_stride'] = 1\n",
    "df['maxpool'] = 1\n",
    "df['dropout'] = 0.0\n",
    "df['batchnorm'] = False\n",
    "df['optimizer']='Adam'\n",
    "df['learning_rate']=0.001\n",
    "df['weight_decay']=0.0\n",
    "df['batch_size']=128\n",
    "df['num_epochs']=5\n",
    "\n",
    "#adjust depth\n",
    "df.at[5:6,'layers'] = 2\n",
    "df.at[11:12,'layers'] = 2\n",
    "\n",
    "\n",
    "#adjust channels\n",
    "df.at[2,'conv_out_channels'] = 32 \n",
    "df.at[3,'conv_out_channels'] = 64\n",
    "df.at[4,'conv_out_channels'] = 128\n",
    "df.at[5,'conv_out_channels'] = 32\n",
    "df.at[6,'conv_out_channels'] = 64\n",
    "df.at[8,'conv_out_channels'] = 32 \n",
    "df.at[9,'conv_out_channels'] = 64\n",
    "df.at[10,'conv_out_channels'] = 128\n",
    "df.at[11,'conv_out_channels'] = 32\n",
    "df.at[12,'conv_out_channels'] = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  2\n",
      "No GPU available.\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Model:  3\n",
      "No GPU available.\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Model:  4\n",
      "No GPU available.\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Model:  5\n",
      "No GPU available.\n",
      "Epoch:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-cab263d0937f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork_tuning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune_architecture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SHAPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_out_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconv_stride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mnet_trained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train_accs'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork_tuning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'valid_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'valid_accs'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork_tuning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'net'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\DTU\\Kandidat\\Deep\\AlgorithmicFairness\\data_utils\\network_tuning23.py\u001b[0m in \u001b[0;36mtune_train\u001b[1;34m(net, data_train, optimizer, learning_rate, weight_decay, batch_size, num_epochs)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m             \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(2,13):\n",
    "    print('Model: ', i)\n",
    "    layers = df.loc[i,'layers']\n",
    "    activations = df.loc[i,'activations']\n",
    "    conv_out_channels = df.loc[i,'conv_out_channels']\n",
    "    kernel_size = df.loc[i,'kernel_size']\n",
    "    conv_stride = df.loc[i,'conv_stride']\n",
    "    maxpool = int(df.loc[i,'maxpool'])\n",
    "    dropout = df.loc[i,'dropout']\n",
    "    batchnorm = df.loc[i,'batchnorm']\n",
    "    optimizer = df.loc[i,'optimizer']\n",
    "    learning_rate = df.loc[i,'learning_rate']\n",
    "    weight_decay = df.loc[i,'weight_decay']\n",
    "    batch_size = int(df.loc[i,'batch_size'])\n",
    "    num_epochs = df.loc[i,'num_epochs']\n",
    "    \n",
    "    net = network_tuning.tune_architecture(layers, activations, IMAGE_SHAPE, conv_out_channels, kernel_size,conv_stride, maxpool, dropout, batchnorm)\n",
    "    net_trained, df.at[i,'train_loss'], df.at[i,'train_accs'] = network_tuning.tune_train(net, data_train, optimizer, learning_rate, weight_decay, batch_size, num_epochs)\n",
    "    df.at[i,'valid_loss'], df.at[i,'valid_accs'] = network_tuning.tune_valid(net, data_valid, batch_size)\n",
    "    df.at[i,'net'] = 'model'+str(i)\n",
    "    df.to_pickle('df.pkl')\n",
    "    torch.save(net_trained.state_dict(), 'model'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c887b38588>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(df.loc[4,'train_accs']).rolling(window=600).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1            NaN\n",
       "2            NaN\n",
       "3            NaN\n",
       "4            NaN\n",
       "          ...   \n",
       "6355    0.916862\n",
       "6356    0.916849\n",
       "6357    0.916732\n",
       "6358    0.916706\n",
       "6359    0.916753\n",
       "Length: 6360, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df.loc[1,'train_accs']).rolling(window=600).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9222146531939507"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df.loc[4,'train_accs'][-400:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>activations</th>\n",
       "      <th>conv_out_channels</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>conv_stride</th>\n",
       "      <th>maxpool</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchnorm</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>net</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accs</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;function relu at 0x000001C881543EA0&gt;, &lt;funct...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>model1</td>\n",
       "      <td>[0.7170678973197937, 4.481327533721924, 1.6229...</td>\n",
       "      <td>[0.5390625, 0.46875, 0.6484375, 0.5703125, 0.6...</td>\n",
       "      <td>0.232076</td>\n",
       "      <td>0.904012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;function relu at 0x000001C881543EA0&gt;, &lt;funct...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>model2</td>\n",
       "      <td>[0.7973788380622864, 10.351090431213379, 5.913...</td>\n",
       "      <td>[0.4921875, 0.546875, 0.5859375, 0.6484375, 0....</td>\n",
       "      <td>0.224289</td>\n",
       "      <td>0.909901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;function relu at 0x000001C881543EA0&gt;, &lt;funct...</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>model3</td>\n",
       "      <td>[0.8159742951393127, 32.093326568603516, 10.63...</td>\n",
       "      <td>[0.40625, 0.4921875, 0.640625, 0.6171875, 0.60...</td>\n",
       "      <td>0.2636</td>\n",
       "      <td>0.894498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;function relu at 0x000001C881543EA0&gt;, &lt;funct...</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>model4</td>\n",
       "      <td>[0.8299558758735657, 41.132080078125, 18.75497...</td>\n",
       "      <td>[0.421875, 0.5546875, 0.6171875, 0.6171875, 0....</td>\n",
       "      <td>0.284481</td>\n",
       "      <td>0.902351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function relu at 0x000001C881543EA0&gt;, &lt;funct...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function relu at 0x000001C881543EA0&gt;, &lt;funct...</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;function tanh at 0x000001C881544950&gt;, &lt;funct...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;function tanh at 0x000001C881544950&gt;, &lt;funct...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;function tanh at 0x000001C881544950&gt;, &lt;funct...</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;function tanh at 0x000001C881544950&gt;, &lt;funct...</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function tanh at 0x000001C881544950&gt;, &lt;funct...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function tanh at 0x000001C881544950&gt;, &lt;funct...</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    layers                                        activations  \\\n",
       "1        1  [<function relu at 0x000001C881543EA0>, <funct...   \n",
       "2        1  [<function relu at 0x000001C881543EA0>, <funct...   \n",
       "3        1  [<function relu at 0x000001C881543EA0>, <funct...   \n",
       "4        1  [<function relu at 0x000001C881543EA0>, <funct...   \n",
       "5        2  [<function relu at 0x000001C881543EA0>, <funct...   \n",
       "6        2  [<function relu at 0x000001C881543EA0>, <funct...   \n",
       "7        1  [<function tanh at 0x000001C881544950>, <funct...   \n",
       "8        1  [<function tanh at 0x000001C881544950>, <funct...   \n",
       "9        1  [<function tanh at 0x000001C881544950>, <funct...   \n",
       "10       1  [<function tanh at 0x000001C881544950>, <funct...   \n",
       "11       2  [<function tanh at 0x000001C881544950>, <funct...   \n",
       "12       2  [<function tanh at 0x000001C881544950>, <funct...   \n",
       "\n",
       "    conv_out_channels  kernel_size  conv_stride  maxpool  dropout  batchnorm  \\\n",
       "1                  16            5            1        1      0.0      False   \n",
       "2                  32            5            1        1      0.0      False   \n",
       "3                  64            5            1        1      0.0      False   \n",
       "4                 128            5            1        1      0.0      False   \n",
       "5                  32            5            1        1      0.0      False   \n",
       "6                  64            5            1        1      0.0      False   \n",
       "7                  16            5            1        1      0.0      False   \n",
       "8                  32            5            1        1      0.0      False   \n",
       "9                  64            5            1        1      0.0      False   \n",
       "10                128            5            1        1      0.0      False   \n",
       "11                 32            5            1        1      0.0      False   \n",
       "12                 64            5            1        1      0.0      False   \n",
       "\n",
       "   optimizer  learning_rate  weight_decay  batch_size  num_epochs     net  \\\n",
       "1       Adam          0.001           0.0         128           5  model1   \n",
       "2       Adam          0.001           0.0         128           5  model2   \n",
       "3       Adam          0.001           0.0         128           5  model3   \n",
       "4       Adam          0.001           0.0         128           5  model4   \n",
       "5       Adam          0.001           0.0         128           5     NaN   \n",
       "6       Adam          0.001           0.0         128           5     NaN   \n",
       "7       Adam          0.001           0.0         128           5     NaN   \n",
       "8       Adam          0.001           0.0         128           5     NaN   \n",
       "9       Adam          0.001           0.0         128           5     NaN   \n",
       "10      Adam          0.001           0.0         128           5     NaN   \n",
       "11      Adam          0.001           0.0         128           5     NaN   \n",
       "12      Adam          0.001           0.0         128           5     NaN   \n",
       "\n",
       "                                           train_loss  \\\n",
       "1   [0.7170678973197937, 4.481327533721924, 1.6229...   \n",
       "2   [0.7973788380622864, 10.351090431213379, 5.913...   \n",
       "3   [0.8159742951393127, 32.093326568603516, 10.63...   \n",
       "4   [0.8299558758735657, 41.132080078125, 18.75497...   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "\n",
       "                                           train_accs valid_loss valid_accs  \n",
       "1   [0.5390625, 0.46875, 0.6484375, 0.5703125, 0.6...   0.232076   0.904012  \n",
       "2   [0.4921875, 0.546875, 0.5859375, 0.6484375, 0....   0.224289   0.909901  \n",
       "3   [0.40625, 0.4921875, 0.640625, 0.6171875, 0.60...     0.2636   0.894498  \n",
       "4   [0.421875, 0.5546875, 0.6171875, 0.6171875, 0....   0.284481   0.902351  \n",
       "5                                                 NaN        NaN        NaN  \n",
       "6                                                 NaN        NaN        NaN  \n",
       "7                                                 NaN        NaN        NaN  \n",
       "8                                                 NaN        NaN        NaN  \n",
       "9                                                 NaN        NaN        NaN  \n",
       "10                                                NaN        NaN        NaN  \n",
       "11                                                NaN        NaN        NaN  \n",
       "12                                                NaN        NaN        NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

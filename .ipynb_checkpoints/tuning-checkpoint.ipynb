{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import data_utils.data_utils_celeba_pytorch as data_utils\n",
    "import data_utils.network_tuning23 as network_tuning\n",
    "from IPython.display import clear_output\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = [73,60,3]\n",
    "# Paths to data\n",
    "TRAIN_PATH =  dataroot + \"\\\\Data\\\\train.csv\" \n",
    "VALID_PATH = dataroot + \"\\\\Data\\\\valid.csv\" \n",
    "TEST_PATH = dataroot + \"\\\\Data\\\\test.csv\" \n",
    "IMAGE_PATHS = \"C:\\\\Users\\\\cfthe\\\\OneDrive\\\\DTU\\\\Kandidat\\\\Deep\\\\celebA\\\\\"\n",
    "TARGET_COL = 'Smiling'\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# train holds both X (input) and t (target/truth)\n",
    "data_train = data_utils.CelebADataset(TRAIN_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\n",
    "data_valid = data_utils.CelebADataset(VALID_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\n",
    "\n",
    "#tuning the network round 1\n",
    "df = pd.DataFrame(index=list(range(1,13)), columns=['layers','activations','conv_out_channels','kernel_size','conv_stride','maxpool'\\\n",
    "                                                    ,'dropout','batchnorm','optimizer','learning_rate','weight_decay','batch_size','num_epochs'\\\n",
    "                                                    ,'net','train_loss','train_accs','valid_loss','valid_accs'])\n",
    "\n",
    "\n",
    "df['layers'] = 1\n",
    "\n",
    "#adjust activation function\n",
    "for i in range(1,7):\n",
    "    df.at[i,'activations'] = [relu, relu, relu, relu]\n",
    "for i in range(7,13):\n",
    "    df.at[i,'activations'] = [tanh, tanh, tanh, tanh]\n",
    "IMAGE_SHAPE = [73,60,3]\n",
    "df['conv_out_channels'] = 16\n",
    "df['kernel_size'] = 5\n",
    "df['conv_stride'] = 1\n",
    "df['maxpool'] = 1\n",
    "df['dropout'] = 0.0\n",
    "df['batchnorm'] = False\n",
    "df['optimizer']='Adam'\n",
    "df['learning_rate']=0.001\n",
    "df['weight_decay']=0.0\n",
    "df['batch_size']=128\n",
    "df['num_epochs']=1\n",
    "\n",
    "#adjust depth\n",
    "df.at[5:6,'layers'] = 2\n",
    "df.at[11:12,'layers'] = 2\n",
    "\n",
    "\n",
    "#adjust channels\n",
    "df.at[2,'conv_out_channels'] = 32 \n",
    "df.at[3,'conv_out_channels'] = 64\n",
    "df.at[4,'conv_out_channels'] = 128\n",
    "df.at[5,'conv_out_channels'] = 32\n",
    "df.at[6,'conv_out_channels'] = 64\n",
    "df.at[8,'conv_out_channels'] = 32 \n",
    "df.at[9,'conv_out_channels'] = 64\n",
    "df.at[10,'conv_out_channels'] = 128\n",
    "df.at[11,'conv_out_channels'] = 32\n",
    "df.at[12,'conv_out_channels'] = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,13):\n",
    "    print('Model: ', i)\n",
    "    layers = df.loc[i,'layers']\n",
    "    activations = df.loc[i,'activations']\n",
    "    conv_out_channels = df.loc[i,'conv_out_channels']\n",
    "    kernel_size = df.loc[i,'kernel_size']\n",
    "    conv_stride = df.loc[i,'conv_stride']\n",
    "    maxpool = int(df.loc[i,'maxpool'])\n",
    "    dropout = df.loc[i,'dropout']\n",
    "    batchnorm = df.loc[i,'batchnorm']\n",
    "    optimizer = df.loc[i,'optimizer']\n",
    "    learning_rate = df.loc[i,'learning_rate']\n",
    "    weight_decay = df.loc[i,'weight_decay']\n",
    "    batch_size = int(df.loc[i,'batch_size'])\n",
    "    num_epochs = df.loc[i,'num_epochs']\n",
    "    \n",
    "    net = network_tuning.tune_architecture(layers, activations, IMAGE_SHAPE, conv_out_channels, kernel_size,conv_stride, maxpool, dropout, batchnorm)\n",
    "    df.at[i,'net'], df.at[i,'train_loss'], df.at[i,'train_accs'] = network_tuning.tune_train(net, data_train, optimizer, learning_rate, weight_decay, batch_size, num_epochs)\n",
    "    df.at[i,'valid_loss'], df.at[i,'valid_accs'] = network_tuning.tune_valid(net, data_valid, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

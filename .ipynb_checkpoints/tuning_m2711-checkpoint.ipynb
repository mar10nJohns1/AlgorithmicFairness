{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps til at køre scriptet:\n",
    "1. Tag en kopi af denne notebook INDEN ændringer laves\n",
    "2. Skriv dit navn (martin/pratt/charlotte) i en string med små bogstaver i variablen nedenfor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eksempel:\n",
    "name = \"martin\" #skal enten være: martin/pratt/charlotte\n",
    "img_path = \"/Users/MartinJohnsen/Documents/Martin Johnsen/MMC/3. Semester/Deep Learning/Projects/Algorithmic fairness/Data/celebA_resize3/\"\n",
    "run = \"run1_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import data_utils.data_utils_celeba_pytorch5 as data_utils\n",
    "import data_utils.network_tuning23 as network_tuning\n",
    "from IPython.display import clear_output\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# Load functions\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout2d, MaxPool2d, BatchNorm2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = [73,60,3]\n",
    "# Paths to data\n",
    "# Root directory for dataset\n",
    "if name==\"charlotte\":\n",
    "    dataroot = '..\\\\AlgorithmicFairness'\n",
    "    TRAIN_PATH =  dataroot + \"\\\\Data\\\\train.csv\" \n",
    "    VALID_PATH = dataroot + \"\\\\Data\\\\valid.csv\" \n",
    "    TEST_PATH = dataroot + \"\\\\Data\\\\test.csv\" \n",
    "    IMAGE_PATHS = \"C:\\\\Users\\\\cfthe\\\\OneDrive\\\\DTU\\\\Kandidat\\\\Deep\\\\celebA_resize3\\\\\"\n",
    "\n",
    "else:\n",
    "    dataroot = '../AlgorithmicFairness'\n",
    "    TRAIN_PATH =  dataroot + \"/Data/train.csv\" \n",
    "    VALID_PATH = dataroot + \"/Data/valid.csv\" \n",
    "    TEST_PATH = dataroot + \"/Data/test.csv\" \n",
    "    IMAGE_PATHS = img_path\n",
    "TARGET_COL = 'Smiling'\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# train holds both X (input) and t (target/truth)\n",
    "data_train = data_utils.CelebADataset(TRAIN_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\n",
    "data_valid = data_utils.CelebADataset(VALID_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\n",
    "\n",
    "#tuning the network round 1\n",
    "df = pd.DataFrame(index=list(range(1,11)), columns=['layers','activations','conv_out_channels','kernel_size','conv_stride','maxpool'\\\n",
    "                                                    ,'dropout','batchnorm','optimizer','learning_rate','weight_decay','batch_size','num_epochs'\\\n",
    "                                                    ,'net','train_loss','train_accs','valid_loss','valid_accs'])\n",
    "\n",
    "df['layers'] = 1\n",
    "\n",
    "#adjust activation function\n",
    "for i in range(1,5):\n",
    "    df.at[i,'activations'] = [relu, relu, relu, relu]\n",
    "for i in range(5,11):\n",
    "    df.at[i,'activations'] = [tanh, tanh, tanh, tanh, tanh, tanh]\n",
    "\n",
    "#inserting combination of activations:\n",
    "df.iloc[0,1][1]= tanh\n",
    "df.iloc[1,1][1]= tanh\n",
    "df.iloc[6,1][1]= relu\n",
    "df.iloc[7,1][1]= relu\n",
    "\n",
    "IMAGE_SHAPE = [73,60,3]\n",
    "df['conv_out_channels'] = 16\n",
    "df['kernel_size'] = 5\n",
    "df['conv_stride'] = 1\n",
    "df['maxpool'] = 1\n",
    "df['dropout'] = 0.0\n",
    "df['batchnorm'] = False\n",
    "df['optimizer']='Adam'\n",
    "df['learning_rate']=0.001\n",
    "df['weight_decay']=0.0\n",
    "df['batch_size']=128\n",
    "df['num_epochs']=5\n",
    "\n",
    "#adjust depth\n",
    "df.at[1:4,'layers'] = 2\n",
    "df.at[7:11,'layers'] = 2\n",
    "\n",
    "#adjust channels\n",
    "df.at[1,'conv_out_channels'] = 32 \n",
    "df.at[2,'conv_out_channels'] = 64\n",
    "df.at[3,'conv_out_channels'] = 32\n",
    "df.at[4,'conv_out_channels'] = 64\n",
    "df.at[5,'conv_out_channels'] = 32\n",
    "df.at[6,'conv_out_channels'] = 128 \n",
    "df.at[7,'conv_out_channels'] = 32\n",
    "df.at[8,'conv_out_channels'] = 64\n",
    "df.at[9,'conv_out_channels'] = 32\n",
    "df.at[10,'conv_out_channels'] = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if name == \"martin\":\n",
    "    df = df.iloc[-3:11,:]\n",
    "elif name == \"pratt\":\n",
    "    df = df.iloc[0:3,:]\n",
    "elif name == \"charlotte\":\n",
    "    df = df.iloc[3:-3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  8\n",
      "No GPU available.\n",
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MartinJohnsen/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Epoch:  2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2137cc299c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_tuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_out_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mnet_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_accs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_tuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid_accs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_tuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_model'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Martin Johnsen/MMC/3. Semester/Deep Learning/Projects/Algorithmic fairness/AlgorithmicFairness/data_utils/network_tuning23.py\u001b[0m in \u001b[0;36mtune_train\u001b[0;34m(net, data_train, optimizer, learning_rate, weight_decay, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in list(df.index):#range(len(df)):\n",
    "    print('Model: ', i)\n",
    "    layers = df.loc[i,'layers']\n",
    "    activations = df.loc[i,'activations']\n",
    "    conv_out_channels = df.loc[i,'conv_out_channels']\n",
    "    kernel_size = df.loc[i,'kernel_size']\n",
    "    conv_stride = df.loc[i,'conv_stride']\n",
    "    maxpool = int(df.loc[i,'maxpool'])\n",
    "    dropout = df.loc[i,'dropout']\n",
    "    batchnorm = df.loc[i,'batchnorm']\n",
    "    optimizer = df.loc[i,'optimizer']\n",
    "    learning_rate = df.loc[i,'learning_rate']\n",
    "    weight_decay = df.loc[i,'weight_decay']\n",
    "    batch_size = int(df.loc[i,'batch_size'])\n",
    "    num_epochs = df.loc[i,'num_epochs']\n",
    "    \n",
    "    net = network_tuning.tune_architecture(layers, activations, IMAGE_SHAPE, conv_out_channels, kernel_size,conv_stride, maxpool, dropout, batchnorm)\n",
    "    net_trained, df.at[i,'train_loss'], df.at[i,'train_accs'] = network_tuning.tune_train(net, data_train, optimizer, learning_rate, weight_decay, batch_size, num_epochs)\n",
    "    df.at[i,'valid_loss'], df.at[i,'valid_accs'] = network_tuning.tune_valid(net, data_valid, batch_size)\n",
    "    df.at[i,'net'] = run+name+'_model'+str(i)\n",
    "    df.to_pickle(run+name+'_df.pkl')\n",
    "    torch.save(net_trained.state_dict(), run+name+'_model'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(pd.Series(df.loc[4,'train_accs']).rolling(window=600).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series(df.loc[1,'train_accs']).rolling(window=600).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/MartinJohnsen/Documents/Martin Johnsen/MMC/3. Semester/Deep Learning/Projects/Algorithmic fairness/AlgorithmicFairness'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/MartinJohnsen/Documents/Martin Johnsen/MMC/3. Semester/Deep Learning/Projects/Algorithmic fairness/AlgorithmicFairness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'/aws/Models/run2__df.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>activations</th>\n",
       "      <th>conv_out_channels</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>conv_stride</th>\n",
       "      <th>maxpool</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchnorm</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>net</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accs</th>\n",
       "      <th>valid_train_loss</th>\n",
       "      <th>valid_train_accs</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function relu at 0x12d1f5b70&gt;, &lt;built-in met...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model1</td>\n",
       "      <td>[0.787320077419281, 1.2756198644638062, 0.6986...</td>\n",
       "      <td>[0.3984375, 0.546875, 0.7109375, 0.671875, 0.6...</td>\n",
       "      <td>[0.7255932688713074, 0.27513042092323303, 0.24...</td>\n",
       "      <td>[0.5130618810653687, 0.8896159529685974, 0.895...</td>\n",
       "      <td>0.207665</td>\n",
       "      <td>0.910455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function relu at 0x12d1f5b70&gt;, &lt;function rel...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model2</td>\n",
       "      <td>[0.7270410656929016, 1.192880392074585, 0.9200...</td>\n",
       "      <td>[0.46875, 0.546875, 0.609375, 0.6171875, 0.710...</td>\n",
       "      <td>[5.199552536010742, 0.27074000239372253, 0.254...</td>\n",
       "      <td>[0.5176926255226135, 0.8867971897125244, 0.894...</td>\n",
       "      <td>0.199299</td>\n",
       "      <td>0.91574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function relu at 0x12d1f5b70&gt;, &lt;function rel...</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model3</td>\n",
       "      <td>[0.8246510624885559, 1.9678641557693481, 1.537...</td>\n",
       "      <td>[0.4140625, 0.5078125, 0.53125, 0.609375, 0.59...</td>\n",
       "      <td>[3.5466063022613525, 0.37123364210128784, 0.27...</td>\n",
       "      <td>[0.4940856695175171, 0.8414456248283386, 0.881...</td>\n",
       "      <td>0.291153</td>\n",
       "      <td>0.89017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function relu at 0x12d1f5b70&gt;, &lt;function rel...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model4</td>\n",
       "      <td>[0.852070152759552, 0.7770803570747375, 0.7371...</td>\n",
       "      <td>[0.390625, 0.6328125, 0.6484375, 0.6171875, 0....</td>\n",
       "      <td>[2.5280070304870605, 0.27008363604545593, 0.23...</td>\n",
       "      <td>[0.46172043681144714, 0.8894146084785461, 0.89...</td>\n",
       "      <td>0.208755</td>\n",
       "      <td>0.913626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>[&lt;function relu at 0x12d1f5b70&gt;, &lt;function rel...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model5</td>\n",
       "      <td>[0.8077120780944824, 1.0716813802719116, 1.078...</td>\n",
       "      <td>[0.453125, 0.6484375, 0.6171875, 0.609375, 0.7...</td>\n",
       "      <td>[0.834692120552063, 0.2967720031738281, 0.2535...</td>\n",
       "      <td>[0.515125572681427, 0.8718478083610535, 0.8921...</td>\n",
       "      <td>0.204349</td>\n",
       "      <td>0.914632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>[&lt;function relu at 0x12d1f5b70&gt;, &lt;function rel...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model6</td>\n",
       "      <td>[0.7874405384063721, 0.8448547720909119, 0.667...</td>\n",
       "      <td>[0.4375, 0.5859375, 0.6484375, 0.640625, 0.648...</td>\n",
       "      <td>[0.7212352156639099, 0.2527103126049042, 0.226...</td>\n",
       "      <td>[0.48104897141456604, 0.8892635703086853, 0.90...</td>\n",
       "      <td>0.22052</td>\n",
       "      <td>0.906075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>[&lt;function relu at 0x12d1f5b70&gt;, &lt;function rel...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model7</td>\n",
       "      <td>[0.7538514733314514, 1.1628611087799072, 1.195...</td>\n",
       "      <td>[0.484375, 0.65625, 0.5859375, 0.65625, 0.6328...</td>\n",
       "      <td>[1.578385353088379, 0.25720539689064026, 0.262...</td>\n",
       "      <td>[0.479337602853775, 0.8903709650039673, 0.8862...</td>\n",
       "      <td>0.211087</td>\n",
       "      <td>0.912267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>[&lt;function relu at 0x12d1f5b70&gt;, &lt;function rel...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model8</td>\n",
       "      <td>[0.7434457540512085, 1.2706197500228882, 0.632...</td>\n",
       "      <td>[0.5859375, 0.5078125, 0.7109375, 0.6640625, 0...</td>\n",
       "      <td>[2.1032886505126953, 0.23763082921504974, 0.23...</td>\n",
       "      <td>[0.48497506976127625, 0.8982231616973877, 0.89...</td>\n",
       "      <td>0.206461</td>\n",
       "      <td>0.911864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layers                                        activations  \\\n",
       "1       2  [<function relu at 0x12d1f5b70>, <built-in met...   \n",
       "2       2  [<function relu at 0x12d1f5b70>, <function rel...   \n",
       "3       2  [<function relu at 0x12d1f5b70>, <function rel...   \n",
       "4       2  [<function relu at 0x12d1f5b70>, <function rel...   \n",
       "5       3  [<function relu at 0x12d1f5b70>, <function rel...   \n",
       "6       4  [<function relu at 0x12d1f5b70>, <function rel...   \n",
       "7       3  [<function relu at 0x12d1f5b70>, <function rel...   \n",
       "8       4  [<function relu at 0x12d1f5b70>, <function rel...   \n",
       "\n",
       "   conv_out_channels  kernel_size  conv_stride  maxpool  dropout  batchnorm  \\\n",
       "1                 32            5            1        2      0.2       True   \n",
       "2                 32            5            1        2      0.2       True   \n",
       "3                 64            5            1        2      0.8       True   \n",
       "4                 32            5            1        2      0.2       True   \n",
       "5                 32            5            1        2      0.2       True   \n",
       "6                 16            5            1        2      0.2       True   \n",
       "7                 32            5            1        2      0.2       True   \n",
       "8                 16            5            1        2      0.2       True   \n",
       "\n",
       "  optimizer  learning_rate  weight_decay  batch_size  num_epochs  \\\n",
       "1      Adam          0.001          0.01         128           5   \n",
       "2      Adam          0.001          0.01         128           5   \n",
       "3      Adam          0.001          0.10         128           5   \n",
       "4      Adam          0.001          0.01         128           5   \n",
       "5      Adam          0.001          0.01         128           5   \n",
       "6      Adam          0.001          0.01         128           5   \n",
       "7      Adam          0.001          0.01         128           5   \n",
       "8      Adam          0.001          0.01         128           5   \n",
       "\n",
       "            net                                         train_loss  \\\n",
       "1  run2__model1  [0.787320077419281, 1.2756198644638062, 0.6986...   \n",
       "2  run2__model2  [0.7270410656929016, 1.192880392074585, 0.9200...   \n",
       "3  run2__model3  [0.8246510624885559, 1.9678641557693481, 1.537...   \n",
       "4  run2__model4  [0.852070152759552, 0.7770803570747375, 0.7371...   \n",
       "5  run2__model5  [0.8077120780944824, 1.0716813802719116, 1.078...   \n",
       "6  run2__model6  [0.7874405384063721, 0.8448547720909119, 0.667...   \n",
       "7  run2__model7  [0.7538514733314514, 1.1628611087799072, 1.195...   \n",
       "8  run2__model8  [0.7434457540512085, 1.2706197500228882, 0.632...   \n",
       "\n",
       "                                          train_accs  \\\n",
       "1  [0.3984375, 0.546875, 0.7109375, 0.671875, 0.6...   \n",
       "2  [0.46875, 0.546875, 0.609375, 0.6171875, 0.710...   \n",
       "3  [0.4140625, 0.5078125, 0.53125, 0.609375, 0.59...   \n",
       "4  [0.390625, 0.6328125, 0.6484375, 0.6171875, 0....   \n",
       "5  [0.453125, 0.6484375, 0.6171875, 0.609375, 0.7...   \n",
       "6  [0.4375, 0.5859375, 0.6484375, 0.640625, 0.648...   \n",
       "7  [0.484375, 0.65625, 0.5859375, 0.65625, 0.6328...   \n",
       "8  [0.5859375, 0.5078125, 0.7109375, 0.6640625, 0...   \n",
       "\n",
       "                                    valid_train_loss  \\\n",
       "1  [0.7255932688713074, 0.27513042092323303, 0.24...   \n",
       "2  [5.199552536010742, 0.27074000239372253, 0.254...   \n",
       "3  [3.5466063022613525, 0.37123364210128784, 0.27...   \n",
       "4  [2.5280070304870605, 0.27008363604545593, 0.23...   \n",
       "5  [0.834692120552063, 0.2967720031738281, 0.2535...   \n",
       "6  [0.7212352156639099, 0.2527103126049042, 0.226...   \n",
       "7  [1.578385353088379, 0.25720539689064026, 0.262...   \n",
       "8  [2.1032886505126953, 0.23763082921504974, 0.23...   \n",
       "\n",
       "                                    valid_train_accs valid_loss valid_accs  \n",
       "1  [0.5130618810653687, 0.8896159529685974, 0.895...   0.207665   0.910455  \n",
       "2  [0.5176926255226135, 0.8867971897125244, 0.894...   0.199299    0.91574  \n",
       "3  [0.4940856695175171, 0.8414456248283386, 0.881...   0.291153    0.89017  \n",
       "4  [0.46172043681144714, 0.8894146084785461, 0.89...   0.208755   0.913626  \n",
       "5  [0.515125572681427, 0.8718478083610535, 0.8921...   0.204349   0.914632  \n",
       "6  [0.48104897141456604, 0.8892635703086853, 0.90...    0.22052   0.906075  \n",
       "7  [0.479337602853775, 0.8903709650039673, 0.8862...   0.211087   0.912267  \n",
       "8  [0.48497506976127625, 0.8982231616973877, 0.89...   0.206461   0.911864  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

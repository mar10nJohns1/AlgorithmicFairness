{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import glob\n",
    "import data_utils.data_utils_celeba as data_utils_celeba\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = '/Users/MartinJohnsen/Documents/Martin Johnsen/MMC/3. Semester/Deep Learning/Projects/Algorithmic fairness/Data/'\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 4\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attributes = pd.read_csv(dataroot+'Anno/list_attr_celeba.txt', sep=\" \")\n",
    "attributes.drop('Unnamed: 41',axis=1, inplace=True)\n",
    "partition = pd.read_csv(dataroot+'Eval/list_eval_partition.txt', sep=\" \", header=None, names=['im_id','partition'])\n",
    "matched = attributes.set_index('im_id').join(partition.set_index('im_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = matched[matched['partition']==0]\n",
    "valid = matched[matched['partition']==1]\n",
    "test = matched[matched['partition']==2]\n",
    "train.to_csv('Data/train.csv')\n",
    "valid.to_csv('Data/valid.csv')\n",
    "test.to_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(\"Data/train_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.groupby(\"Young\").count()\n",
    "#df = df.groupby('domain')['ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n",
      "\t0 of 162770\n",
      "\t10000 of 162770\n",
      "\t20000 of 162770\n",
      "\t30000 of 162770\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (178,218)\n",
    "# Paths to data\n",
    "TRAIN_PATH = \"Data/train_full.csv\" \n",
    "VALID_PATH = \"Data/valid_full.csv\" \n",
    "TEST_PATH = \"Data/test_full.csv\" \n",
    "IMAGE_PATHS = glob.glob('/Users/MartinJohnsen/Documents/Martin Johnsen/MMC/3. Semester/Deep Learning/Projects/Algorithmic fairness/Data/celeba/*.jpg')\n",
    "TARGET_COL = 'Smiling'\n",
    "\n",
    "# train holds both X (input) and t (target/truth)\n",
    "data = data_utils_celeba.load_data(train_path=TRAIN_PATH,\n",
    "                            valid_path = VALID_PATH,\n",
    "                            test_path=TEST_PATH,\n",
    "                            image_paths=IMAGE_PATHS,\n",
    "                            target_col = TARGET_COL,\n",
    "                            image_shape=IMAGE_SHAPE[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "## Dump the data into a pickle file\n",
    "#\n",
    "#with open('celeba_dataset.pickle', 'wb') as f:\n",
    "#    pickle.dump(data, f)\n",
    "    \n",
    "## Load the data from a pickle file\n",
    "#with open('Kaggle/data.pickle', 'rb') as f:\n",
    "#    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "\n",
    "dummy_batch_gen = data_utils_celeba.batch_generator(data, batch_size=batch_size, num_classes=NUM_CLASSES, num_iterations=5e3, num_features=40, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = next(dummy_batch_gen.gen_train())\n",
    "valid_batch, i = next(dummy_batch_gen.gen_valid())\n",
    "test_batch, i = next(dummy_batch_gen.gen_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(vutils.make_grid(torch.Tensor(valid_batch['images'][1]), padding=2, normalize=True).cpu(),(0,1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functions\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")\n",
    "\n",
    "\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the dimensions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image shape should be of the format (height, width, channels)\n",
    "IMAGE_SHAPE = (178, 218, 3)   # Channel 1 due to B/W images\n",
    "NUM_CLASSES =    # Different flowers\n",
    "\n",
    "# For all three features types margin, shape, and texture, we have NUM_FEATURES for each type.\n",
    "NUM_FEATURES = 64  # <-- Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining convolutional dimensions\n",
    "This formula defines the number of features in both the height and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conv_dim(dim_size):\n",
    "    return int((dim_size - kernel_size + 2 * conv_pad) / conv_stride + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

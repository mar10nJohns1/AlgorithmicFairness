{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "1. import packages and defining paths\n",
    "2. defining model dataframe\n",
    "3. run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import packages and defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eksempel:\n",
    "name = None #skal enten v√¶re: martin/pratt/charlotte\n",
    "run = \"run3_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import data_utils.data_utils_celeba_pytorch5 as data_utils\n",
    "import data_utils.network_tuning_valid as network_tuning\n",
    "from IPython.display import clear_output\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# Load functions\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout2d, MaxPool2d, BatchNorm2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = [73,60,3]\n",
    "# Paths to data\n",
    "# Root directory for dataset\n",
    "if name==\"charlotte\":\n",
    "    dataroot = '..\\\\AlgorithmicFairness'\n",
    "    TRAIN_PATH =  dataroot + \"\\\\Data\\\\train.csv\" \n",
    "    VALID_PATH = dataroot + \"\\\\Data\\\\valid.csv\" \n",
    "    TEST_PATH = dataroot + \"\\\\Data\\\\test.csv\" \n",
    "    IMAGE_PATHS = \"C:\\\\Users\\\\cfthe\\\\OneDrive\\\\DTU\\\\Kandidat\\\\Deep\\\\celebA_resize3\\\\\"\n",
    "\n",
    "else:\n",
    "    dataroot = '../AlgorithmicFairness'\n",
    "    TRAIN_PATH =  dataroot + \"/Data/train.csv\" \n",
    "    VALID_PATH = dataroot + \"/Data/valid.csv\" \n",
    "    TEST_PATH = dataroot + \"/Data/test.csv\" \n",
    "    IMAGE_PATHS = \"/Users/MartinJohnsen/Documents/Martin Johnsen/MMC/3. Semester/Deep Learning/Projects/Algorithmic fairness/Data/celebA_resize3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataroot+\"/Data/train.csv\")\n",
    "attrubutes = list(df.columns)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTARGET_COL = 'Smiling'\\nNUM_CLASSES = 2\\n\\n# train holds both X (input) and t (target/truth)\\ndata_train = data_utils.CelebADataset(TRAIN_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\\ndata_valid = data_utils.CelebADataset(VALID_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This column is now also defined in the loop below, as we need to loop through all the different attributes\n",
    "\"\"\"\n",
    "TARGET_COL = 'Smiling'\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# train holds both X (input) and t (target/truth)\n",
    "data_train = data_utils.CelebADataset(TRAIN_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\n",
    "data_valid = data_utils.CelebADataset(VALID_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading df from run 2:\n",
    "df = pd.read_pickle('models/aws_models/run2__df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>activations</th>\n",
       "      <th>conv_out_channels</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>conv_stride</th>\n",
       "      <th>maxpool</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batchnorm</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>net</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accs</th>\n",
       "      <th>valid_train_loss</th>\n",
       "      <th>valid_train_accs</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function relu at 0x11dcc2f28&gt;, &lt;built-in met...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model1</td>\n",
       "      <td>[0.787320077419281, 1.2756198644638062, 0.6986...</td>\n",
       "      <td>[0.3984375, 0.546875, 0.7109375, 0.671875, 0.6...</td>\n",
       "      <td>[0.7255932688713074, 0.27513042092323303, 0.24...</td>\n",
       "      <td>[0.5130618810653687, 0.8896159529685974, 0.895...</td>\n",
       "      <td>0.207665</td>\n",
       "      <td>0.910455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function relu at 0x11dcc2f28&gt;, &lt;function rel...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model2</td>\n",
       "      <td>[0.7270410656929016, 1.192880392074585, 0.9200...</td>\n",
       "      <td>[0.46875, 0.546875, 0.609375, 0.6171875, 0.710...</td>\n",
       "      <td>[5.199552536010742, 0.27074000239372253, 0.254...</td>\n",
       "      <td>[0.5176926255226135, 0.8867971897125244, 0.894...</td>\n",
       "      <td>0.199299</td>\n",
       "      <td>0.91574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function relu at 0x11dcc2f28&gt;, &lt;function rel...</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model3</td>\n",
       "      <td>[0.8246510624885559, 1.9678641557693481, 1.537...</td>\n",
       "      <td>[0.4140625, 0.5078125, 0.53125, 0.609375, 0.59...</td>\n",
       "      <td>[3.5466063022613525, 0.37123364210128784, 0.27...</td>\n",
       "      <td>[0.4940856695175171, 0.8414456248283386, 0.881...</td>\n",
       "      <td>0.291153</td>\n",
       "      <td>0.89017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;function relu at 0x11dcc2f28&gt;, &lt;function rel...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model4</td>\n",
       "      <td>[0.852070152759552, 0.7770803570747375, 0.7371...</td>\n",
       "      <td>[0.390625, 0.6328125, 0.6484375, 0.6171875, 0....</td>\n",
       "      <td>[2.5280070304870605, 0.27008363604545593, 0.23...</td>\n",
       "      <td>[0.46172043681144714, 0.8894146084785461, 0.89...</td>\n",
       "      <td>0.208755</td>\n",
       "      <td>0.913626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>[&lt;function relu at 0x11dcc2f28&gt;, &lt;function rel...</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>run2__model5</td>\n",
       "      <td>[0.8077120780944824, 1.0716813802719116, 1.078...</td>\n",
       "      <td>[0.453125, 0.6484375, 0.6171875, 0.609375, 0.7...</td>\n",
       "      <td>[0.834692120552063, 0.2967720031738281, 0.2535...</td>\n",
       "      <td>[0.515125572681427, 0.8718478083610535, 0.8921...</td>\n",
       "      <td>0.204349</td>\n",
       "      <td>0.914632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layers                                        activations  \\\n",
       "1       2  [<function relu at 0x11dcc2f28>, <built-in met...   \n",
       "2       2  [<function relu at 0x11dcc2f28>, <function rel...   \n",
       "3       2  [<function relu at 0x11dcc2f28>, <function rel...   \n",
       "4       2  [<function relu at 0x11dcc2f28>, <function rel...   \n",
       "5       3  [<function relu at 0x11dcc2f28>, <function rel...   \n",
       "\n",
       "   conv_out_channels  kernel_size  conv_stride  maxpool  dropout  batchnorm  \\\n",
       "1                 32            5            1        2      0.2       True   \n",
       "2                 32            5            1        2      0.2       True   \n",
       "3                 64            5            1        2      0.8       True   \n",
       "4                 32            5            1        2      0.2       True   \n",
       "5                 32            5            1        2      0.2       True   \n",
       "\n",
       "  optimizer  learning_rate  weight_decay  batch_size  num_epochs  \\\n",
       "1      Adam          0.001          0.01         128           5   \n",
       "2      Adam          0.001          0.01         128           5   \n",
       "3      Adam          0.001          0.10         128           5   \n",
       "4      Adam          0.001          0.01         128           5   \n",
       "5      Adam          0.001          0.01         128           5   \n",
       "\n",
       "            net                                         train_loss  \\\n",
       "1  run2__model1  [0.787320077419281, 1.2756198644638062, 0.6986...   \n",
       "2  run2__model2  [0.7270410656929016, 1.192880392074585, 0.9200...   \n",
       "3  run2__model3  [0.8246510624885559, 1.9678641557693481, 1.537...   \n",
       "4  run2__model4  [0.852070152759552, 0.7770803570747375, 0.7371...   \n",
       "5  run2__model5  [0.8077120780944824, 1.0716813802719116, 1.078...   \n",
       "\n",
       "                                          train_accs  \\\n",
       "1  [0.3984375, 0.546875, 0.7109375, 0.671875, 0.6...   \n",
       "2  [0.46875, 0.546875, 0.609375, 0.6171875, 0.710...   \n",
       "3  [0.4140625, 0.5078125, 0.53125, 0.609375, 0.59...   \n",
       "4  [0.390625, 0.6328125, 0.6484375, 0.6171875, 0....   \n",
       "5  [0.453125, 0.6484375, 0.6171875, 0.609375, 0.7...   \n",
       "\n",
       "                                    valid_train_loss  \\\n",
       "1  [0.7255932688713074, 0.27513042092323303, 0.24...   \n",
       "2  [5.199552536010742, 0.27074000239372253, 0.254...   \n",
       "3  [3.5466063022613525, 0.37123364210128784, 0.27...   \n",
       "4  [2.5280070304870605, 0.27008363604545593, 0.23...   \n",
       "5  [0.834692120552063, 0.2967720031738281, 0.2535...   \n",
       "\n",
       "                                    valid_train_accs valid_loss valid_accs  \n",
       "1  [0.5130618810653687, 0.8896159529685974, 0.895...   0.207665   0.910455  \n",
       "2  [0.5176926255226135, 0.8867971897125244, 0.894...   0.199299    0.91574  \n",
       "3  [0.4940856695175171, 0.8414456248283386, 0.881...   0.291153    0.89017  \n",
       "4  [0.46172043681144714, 0.8894146084785461, 0.89...   0.208755   0.913626  \n",
       "5  [0.515125572681427, 0.8718478083610535, 0.8921...   0.204349   0.914632  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model numbber 2 is the best one..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining model dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning the network round 1\n",
    "df = pd.DataFrame(index=list(range(1,41)), columns=['target','layers','activations','conv_out_channels','kernel_size','conv_stride','maxpool'\\\n",
    "                                                    ,'dropout','batchnorm','optimizer','learning_rate','weight_decay','batch_size','num_epochs'\\\n",
    "                                                    ,'net','train_loss','train_accs','valid_train_loss','valid_train_accs','valid_loss','valid_accs'])\n",
    "\n",
    "df['layers'] = 2\n",
    "\n",
    "#adjust activation function\n",
    "for i in range(1,41):\n",
    "    df.at[i,'activations'] = [relu, relu, relu, relu]\n",
    "\n",
    "df['conv_out_channels'] = 32\n",
    "df['kernel_size'] = 5\n",
    "df['conv_stride'] = 1\n",
    "df['maxpool'] = 2\n",
    "df['dropout'] = 0.2\n",
    "df['batchnorm'] = True\n",
    "df['optimizer']='Adam'\n",
    "df['learning_rate']=0.001\n",
    "df['weight_decay']=0.01\n",
    "df['batch_size']=128\n",
    "df['num_epochs']=5\n",
    "\n",
    "#From when tuning model (now we are only using the best one)\n",
    "#df.at[1,'activations'] = [relu, torch.tanh]\n",
    "#df.at[5,'activations'] = [relu, relu, torch.tanh]\n",
    "#df.at[6,'activations'] = [relu, relu, relu, torch.tanh]\n",
    "\n",
    "#adjust depth\n",
    "#df.at[5,'layers'] = 3\n",
    "#df.at[6,'layers'] = 4\n",
    "#df.at[7,'layers'] = 3\n",
    "#df.at[8,'layers'] = 4\n",
    "\n",
    "#adjust channels\n",
    "#df.at[3,'conv_out_channels'] = 64\n",
    "#df.at[6,'conv_out_channels'] = 16\n",
    "#df.at[8,'conv_out_channels'] = 16\n",
    "\n",
    "#adjust dropout and weigth decay\n",
    "#df.at[3,'dropout'] = 0.8\n",
    "#df.at[3,'weight_decay']=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding all the different attributes as a column in the dataframe\n",
    "df.target = attrubutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  1\n",
      "No GPU available.\n",
      "Epoch:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-442fc33c9e30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_tuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_out_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mnet_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_accs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid_train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid_train_accs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_tuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid_accs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_tuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_model'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Martin Johnsen/MMC/3. Semester/Deep Learning/Projects/Algorithmic fairness/AlgorithmicFairness/data_utils/network_tuning_valid.py\u001b[0m in \u001b[0;36mtune_train\u001b[0;34m(net, data_train, data_valid, optimizer, learning_rate, weight_decay, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m300\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0mvalid_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mvalid_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Martin Johnsen/MMC/3. Semester/Deep Learning/Projects/Algorithmic fairness/AlgorithmicFairness/data_utils/network_tuning_valid.py\u001b[0m in \u001b[0;36mtune_valid\u001b[0;34m(net, data_valid, batch_size)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_valid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_gen_valid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mget_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mlabels_argmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mval_losses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_argmax\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Martin Johnsen/MMC/3. Semester/Deep Learning/Projects/Algorithmic fairness/AlgorithmicFairness/data_utils/network_tuning_valid.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_img)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mfeatures_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mfeatures_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in list(df.index):#range(len(df)):\n",
    "    ## This column is now also defined in the loop below, as we need to loop through all the different attributes\n",
    "    TARGET_COL = df.loc[i,'target']\n",
    "    # train holds both X (input) and t (target/truth)\n",
    "    data_train = data_utils.CelebADataset(TRAIN_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\n",
    "    data_valid = data_utils.CelebADataset(VALID_PATH,IMAGE_PATHS,IMAGE_SHAPE,TARGET_COL)\n",
    "    \n",
    "    print('Model: ', i)\n",
    "    layers = df.loc[i,'layers']\n",
    "    activations = df.loc[i,'activations']\n",
    "    conv_out_channels = df.loc[i,'conv_out_channels']\n",
    "    kernel_size = df.loc[i,'kernel_size']\n",
    "    conv_stride = df.loc[i,'conv_stride']\n",
    "    maxpool = int(df.loc[i,'maxpool'])\n",
    "    dropout = df.loc[i,'dropout']\n",
    "    batchnorm = df.loc[i,'batchnorm']\n",
    "    optimizer = df.loc[i,'optimizer']\n",
    "    learning_rate = df.loc[i,'learning_rate']\n",
    "    weight_decay = df.loc[i,'weight_decay']\n",
    "    batch_size = int(df.loc[i,'batch_size'])\n",
    "    num_epochs = df.loc[i,'num_epochs']\n",
    "    \n",
    "    net = network_tuning.tune_architecture(layers, activations, IMAGE_SHAPE, conv_out_channels, kernel_size,conv_stride, maxpool, dropout, batchnorm)\n",
    "    net_trained, df.at[i,'train_loss'], df.at[i,'train_accs'], df.at[i,'valid_train_loss'], df.at[i,'valid_train_accs'] = network_tuning.tune_train(net, data_train, data_valid, optimizer, learning_rate, weight_decay, batch_size, num_epochs)\n",
    "    df.at[i,'valid_loss'], df.at[i,'valid_accs'] = network_tuning.tune_valid(net, data_valid, batch_size)\n",
    "    df.at[i,'net'] = run+'_model'+str(i)\n",
    "    df.to_pickle(run+'df.pkl')\n",
    "    torch.save(net_trained.state_dict(), run+TARGET_COL+'_model'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(pd.Series(df.loc[4,'train_accs']).rolling(window=600).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series(df.loc[1,'train_accs']).rolling(window=600).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(df.loc[1,'train_accs'])\n",
    "plt.plot([600,1200,1800,2400,3000,3600,4200,4800,5400,6000],df.loc[1,'valid_train_accs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,600,1200,1800,2400,3000,3600,4200,4800,5400],df.loc[1,'valid_train_accs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
